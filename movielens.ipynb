{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Factorization machines workshop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://movielens.org - некоммерческая рекомендательная система\n",
    "\n",
    "https://grouplens.org/datasets/movielens/ - datasets с сайта.\n",
    "\n",
    "100k - малый dataset, 20M - большой"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  /tmp/ml-20m.zip\n",
      "   creating: ./ml-20m/\n",
      "  inflating: ./ml-20m/genome-scores.csv  \n",
      "  inflating: ./ml-20m/genome-tags.csv  \n",
      "  inflating: ./ml-20m/links.csv      \n",
      "  inflating: ./ml-20m/movies.csv     \n",
      "  inflating: ./ml-20m/ratings.csv    \n",
      "  inflating: ./ml-20m/README.txt     \n",
      "  inflating: ./ml-20m/tags.csv       \n"
     ]
    }
   ],
   "source": [
    "!unzip /tmp/ml-20m.zip -d ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  /tmp/ml-100k.zip\n",
      "   creating: ./ml-100k/\n",
      "  inflating: ./ml-100k/allbut.pl     \n",
      "  inflating: ./ml-100k/mku.sh        \n",
      "  inflating: ./ml-100k/README        \n",
      "  inflating: ./ml-100k/u.data        \n",
      "  inflating: ./ml-100k/u.genre       \n",
      "  inflating: ./ml-100k/u.info        \n",
      "  inflating: ./ml-100k/u.item        \n",
      "  inflating: ./ml-100k/u.occupation  \n",
      "  inflating: ./ml-100k/u.user        \n",
      "  inflating: ./ml-100k/u1.base       \n",
      "  inflating: ./ml-100k/u1.test       \n",
      "  inflating: ./ml-100k/u2.base       \n",
      "  inflating: ./ml-100k/u2.test       \n",
      "  inflating: ./ml-100k/u3.base       \n",
      "  inflating: ./ml-100k/u3.test       \n",
      "  inflating: ./ml-100k/u4.base       \n",
      "  inflating: ./ml-100k/u4.test       \n",
      "  inflating: ./ml-100k/u5.base       \n",
      "  inflating: ./ml-100k/u5.test       \n",
      "  inflating: ./ml-100k/ua.base       \n",
      "  inflating: ./ml-100k/ua.test       \n",
      "  inflating: ./ml-100k/ub.base       \n",
      "  inflating: ./ml-100k/ub.test       \n"
     ]
    }
   ],
   "source": [
    "!unzip /tmp/ml-100k.zip -d ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "README\t   u.data   u.item\t  u1.base  u2.test  u4.base  u5.test  ub.base\r\n",
      "allbut.pl  u.genre  u.occupation  u1.test  u3.base  u4.test  ua.base  ub.test\r\n",
      "mku.sh\t   u.info   u.user\t  u2.base  u3.test  u5.base  ua.test\r\n"
     ]
    }
   ],
   "source": [
    "!ls ml-100k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>info</th>\n",
       "      <th>user_id</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>occupation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1|24|M|technician|85711</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>M</td>\n",
       "      <td>technician</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2|53|F|other|94043</td>\n",
       "      <td>2</td>\n",
       "      <td>53</td>\n",
       "      <td>F</td>\n",
       "      <td>other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3|23|M|writer|32067</td>\n",
       "      <td>3</td>\n",
       "      <td>23</td>\n",
       "      <td>M</td>\n",
       "      <td>writer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4|24|M|technician|43537</td>\n",
       "      <td>4</td>\n",
       "      <td>24</td>\n",
       "      <td>M</td>\n",
       "      <td>technician</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5|33|F|other|15213</td>\n",
       "      <td>5</td>\n",
       "      <td>33</td>\n",
       "      <td>F</td>\n",
       "      <td>other</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      info user_id age gender  occupation\n",
       "0  1|24|M|technician|85711       1  24      M  technician\n",
       "1       2|53|F|other|94043       2  53      F       other\n",
       "2      3|23|M|writer|32067       3  23      M      writer\n",
       "3  4|24|M|technician|43537       4  24      M  technician\n",
       "4       5|33|F|other|15213       5  33      F       other"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user = pd.read_csv('ml-100k/u.user', header=None, names=['info'])\n",
    "user['user_id'] = user['info'].apply(lambda rec: rec.split('|')[0])\n",
    "user['age'] = user['info'].apply(lambda rec: rec.split('|')[1])\n",
    "user['gender'] = user['info'].apply(lambda rec: rec.split('|')[2])\n",
    "user['occupation'] = user['info'].apply(lambda rec: rec.split('|')[3])\n",
    "user.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>info</th>\n",
       "      <th>movie_id</th>\n",
       "      <th>title</th>\n",
       "      <th>Action</th>\n",
       "      <th>Adventure</th>\n",
       "      <th>Animation</th>\n",
       "      <th>Childrens</th>\n",
       "      <th>Comedy</th>\n",
       "      <th>Crime</th>\n",
       "      <th>Documentary</th>\n",
       "      <th>...</th>\n",
       "      <th>Fantasy</th>\n",
       "      <th>Film-Noir</th>\n",
       "      <th>Horror</th>\n",
       "      <th>Musical</th>\n",
       "      <th>Mystery</th>\n",
       "      <th>Romance</th>\n",
       "      <th>Sci-Fi</th>\n",
       "      <th>Thriller</th>\n",
       "      <th>War</th>\n",
       "      <th>Western</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1|Toy Story (1995)|01-Jan-1995||http://us.imdb...</td>\n",
       "      <td>1</td>\n",
       "      <td>Toy Story (1995)</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2|GoldenEye (1995)|01-Jan-1995||http://us.imdb...</td>\n",
       "      <td>2</td>\n",
       "      <td>GoldenEye (1995)</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3|Four Rooms (1995)|01-Jan-1995||http://us.imd...</td>\n",
       "      <td>3</td>\n",
       "      <td>Four Rooms (1995)</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4|Get Shorty (1995)|01-Jan-1995||http://us.imd...</td>\n",
       "      <td>4</td>\n",
       "      <td>Get Shorty (1995)</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5|Copycat (1995)|01-Jan-1995||http://us.imdb.c...</td>\n",
       "      <td>5</td>\n",
       "      <td>Copycat (1995)</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                info movie_id  \\\n",
       "0  1|Toy Story (1995)|01-Jan-1995||http://us.imdb...        1   \n",
       "1  2|GoldenEye (1995)|01-Jan-1995||http://us.imdb...        2   \n",
       "2  3|Four Rooms (1995)|01-Jan-1995||http://us.imd...        3   \n",
       "3  4|Get Shorty (1995)|01-Jan-1995||http://us.imd...        4   \n",
       "4  5|Copycat (1995)|01-Jan-1995||http://us.imdb.c...        5   \n",
       "\n",
       "               title Action Adventure Animation Childrens Comedy Crime  \\\n",
       "0   Toy Story (1995)      0         0         1         1      1     0   \n",
       "1   GoldenEye (1995)      1         1         0         0      0     0   \n",
       "2  Four Rooms (1995)      0         0         0         0      0     0   \n",
       "3  Get Shorty (1995)      1         0         0         0      1     0   \n",
       "4     Copycat (1995)      0         0         0         0      0     1   \n",
       "\n",
       "  Documentary   ...   Fantasy Film-Noir Horror Musical Mystery Romance Sci-Fi  \\\n",
       "0           0   ...         0         0      0       0       0       0      0   \n",
       "1           0   ...         0         0      0       0       0       0      0   \n",
       "2           0   ...         0         0      0       0       0       0      0   \n",
       "3           0   ...         0         0      0       0       0       0      0   \n",
       "4           0   ...         0         0      0       0       0       0      0   \n",
       "\n",
       "  Thriller War Western  \n",
       "0        0   0       0  \n",
       "1        1   0       0  \n",
       "2        1   0       0  \n",
       "3        0   0       0  \n",
       "4        1   0       0  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie = pd.read_csv('ml-100k/u.item', header=None, names=['info'])\n",
    "movie['movie_id'] = movie['info'].apply(lambda rec: rec.split('|')[0])\n",
    "movie['title'] = movie['info'].apply(lambda rec: rec.split('|')[1])\n",
    "movie['Action'] = movie['info'].apply(lambda rec: rec.split('|')[6] if len(rec.split('|')) == 24 else 0)\n",
    "movie['Adventure'] = movie['info'].apply(lambda rec: rec.split('|')[7] if len(rec.split('|')) == 24 else 0)\n",
    "movie['Animation'] = movie['info'].apply(lambda rec: rec.split('|')[8] if len(rec.split('|')) == 24 else 0)\n",
    "movie['Childrens'] = movie['info'].apply(lambda rec: rec.split('|')[9] if len(rec.split('|')) == 24 else 0)\n",
    "movie['Comedy'] = movie['info'].apply(lambda rec: rec.split('|')[10] if len(rec.split('|')) == 24 else 0)\n",
    "movie['Crime'] = movie['info'].apply(lambda rec: rec.split('|')[11] if len(rec.split('|')) == 24 else 0)\n",
    "movie['Documentary'] = movie['info'].apply(lambda rec: rec.split('|')[12] if len(rec.split('|')) == 24 else 0)\n",
    "movie['Drama'] = movie['info'].apply(lambda rec: rec.split('|')[13] if len(rec.split('|')) == 24 else 0)\n",
    "movie['Fantasy'] = movie['info'].apply(lambda rec: rec.split('|')[14] if len(rec.split('|')) == 24 else 0)\n",
    "movie['Film-Noir'] = movie['info'].apply(lambda rec: rec.split('|')[15] if len(rec.split('|')) == 24 else 0)\n",
    "movie['Horror'] = movie['info'].apply(lambda rec: rec.split('|')[16] if len(rec.split('|')) == 24 else 0)\n",
    "movie['Musical'] = movie['info'].apply(lambda rec: rec.split('|')[17] if len(rec.split('|')) == 24 else 0)\n",
    "movie['Mystery'] = movie['info'].apply(lambda rec: rec.split('|')[18] if len(rec.split('|')) == 24 else 0)\n",
    "movie['Romance'] = movie['info'].apply(lambda rec: rec.split('|')[19] if len(rec.split('|')) == 24 else 0)\n",
    "movie['Sci-Fi'] = movie['info'].apply(lambda rec: rec.split('|')[20] if len(rec.split('|')) == 24 else 0)\n",
    "movie['Thriller'] = movie['info'].apply(lambda rec: rec.split('|')[21] if len(rec.split('|')) == 24 else 0)\n",
    "movie['War'] = movie['info'].apply(lambda rec: rec.split('|')[22] if len(rec.split('|')) == 24 else 0)\n",
    "movie['Western'] = movie['info'].apply(lambda rec: rec.split('|')[23] if len(rec.split('|')) == 24 else 0)\n",
    "movie.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>info</th>\n",
       "      <th>user_id</th>\n",
       "      <th>movie_id</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>196\\t242\\t3\\t881250949</td>\n",
       "      <td>196</td>\n",
       "      <td>242</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>186\\t302\\t3\\t891717742</td>\n",
       "      <td>186</td>\n",
       "      <td>302</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22\\t377\\t1\\t878887116</td>\n",
       "      <td>22</td>\n",
       "      <td>377</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>244\\t51\\t2\\t880606923</td>\n",
       "      <td>244</td>\n",
       "      <td>51</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>166\\t346\\t1\\t886397596</td>\n",
       "      <td>166</td>\n",
       "      <td>346</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     info user_id movie_id rating\n",
       "0  196\\t242\\t3\\t881250949     196      242      3\n",
       "1  186\\t302\\t3\\t891717742     186      302      3\n",
       "2   22\\t377\\t1\\t878887116      22      377      1\n",
       "3   244\\t51\\t2\\t880606923     244       51      2\n",
       "4  166\\t346\\t1\\t886397596     166      346      1"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings = pd.read_csv('ml-100k/u.data', header=None, names=['info'])\n",
    "ratings['user_id'] = ratings['info'].apply(lambda rec: rec.split('\\t')[0])\n",
    "ratings['movie_id'] = ratings['info'].apply(lambda rec: rec.split('\\t')[1])\n",
    "ratings['rating'] = ratings['info'].apply(lambda rec: rec.split('\\t')[2])\n",
    "ratings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = ratings.merge(user, on='user_id').merge(movie, on='movie_id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error, log_loss\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from pyfm import pylibfm\n",
    "\n",
    "\n",
    "# Read in data\n",
    "def loadData(filename,path=\"ml-100k/\"):\n",
    "    data = []\n",
    "    y = []\n",
    "    users=set()\n",
    "    items=set()\n",
    "    with open(path+filename) as f:\n",
    "        for line in f:\n",
    "            (user,movieid,rating,ts)=line.split('\\t')\n",
    "            data.append({ \"user_id\": str(user), \"movie_id\": str(movieid)})\n",
    "            y.append(float(rating))\n",
    "            users.add(user)\n",
    "            items.add(movieid)\n",
    "\n",
    "    return (data, np.array(y), users, items)\n",
    "\n",
    "(train_data, y_train, train_users, train_items) = loadData(\"ua.base\")\n",
    "(test_data, y_test, test_users, test_items) = loadData(\"ua.test\")\n",
    "v = DictVectorizer()\n",
    "X_train = v.fit_transform(train_data)\n",
    "X_test = v.transform(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.82847107974499679, 0.92806375584295875)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = LinearRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "train_score = mean_squared_error(y_train, lr.predict(X_train))\n",
    "test_score = mean_squared_error(y_test, lr.predict(X_test))\n",
    "train_score, test_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>info</th>\n",
       "      <th>user_id</th>\n",
       "      <th>movie_id</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>308\\t1\\t4\\t887736532</td>\n",
       "      <td>308</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    info user_id movie_id rating\n",
       "24  308\\t1\\t4\\t887736532     308        1      4"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings[(ratings.user_id == '308') & (ratings.movie_id == '1')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1912]\n",
      "[0]\n"
     ]
    }
   ],
   "source": [
    "ex = v.transform([{'user_id': '308'}])\n",
    "print ex.indices\n",
    "ex = v.transform([{'movie_id': '1'}])\n",
    "print ex.indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.53830791489356944, -0.15291660287472478, 3.5238268742409184)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.coef_[0], lr.coef_[1912], lr.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.9092181862597633"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.53830791489356944 + (-0.15291660287472478) + 3.5238268742409184"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 3.90921819]\n"
     ]
    }
   ],
   "source": [
    "ex = v.transform([{'user_id': '308', 'movie_id': '1'}])\n",
    "print lr.predict(ex)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Factorization machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating validation dataset of 0.01 of training for adaptive regularization\n",
      "-- Epoch 1\n",
      "Training MSE: 0.59498\n",
      "-- Epoch 2\n",
      "Training MSE: 0.51803\n",
      "-- Epoch 3\n",
      "Training MSE: 0.49009\n",
      "-- Epoch 4\n",
      "Training MSE: 0.47416\n",
      "-- Epoch 5\n",
      "Training MSE: 0.46351\n",
      "-- Epoch 6\n",
      "Training MSE: 0.45599\n",
      "-- Epoch 7\n",
      "Training MSE: 0.45005\n",
      "-- Epoch 8\n",
      "Training MSE: 0.44539\n",
      "-- Epoch 9\n",
      "Training MSE: 0.44151\n",
      "-- Epoch 10\n",
      "Training MSE: 0.43830\n",
      "-- Epoch 11\n",
      "Training MSE: 0.43543\n",
      "-- Epoch 12\n",
      "Training MSE: 0.43283\n",
      "-- Epoch 13\n",
      "Training MSE: 0.43058\n",
      "-- Epoch 14\n",
      "Training MSE: 0.42849\n",
      "-- Epoch 15\n",
      "Training MSE: 0.42652\n",
      "-- Epoch 16\n",
      "Training MSE: 0.42479\n",
      "-- Epoch 17\n",
      "Training MSE: 0.42315\n",
      "-- Epoch 18\n",
      "Training MSE: 0.42159\n",
      "-- Epoch 19\n",
      "Training MSE: 0.42012\n",
      "-- Epoch 20\n",
      "Training MSE: 0.41873\n",
      "-- Epoch 21\n",
      "Training MSE: 0.41730\n",
      "-- Epoch 22\n",
      "Training MSE: 0.41595\n",
      "-- Epoch 23\n",
      "Training MSE: 0.41465\n",
      "-- Epoch 24\n",
      "Training MSE: 0.41327\n",
      "-- Epoch 25\n",
      "Training MSE: 0.41203\n",
      "-- Epoch 26\n",
      "Training MSE: 0.41058\n",
      "-- Epoch 27\n",
      "Training MSE: 0.40918\n",
      "-- Epoch 28\n",
      "Training MSE: 0.40780\n",
      "-- Epoch 29\n",
      "Training MSE: 0.40633\n",
      "-- Epoch 30\n",
      "Training MSE: 0.40472\n",
      "-- Epoch 31\n",
      "Training MSE: 0.40323\n",
      "-- Epoch 32\n",
      "Training MSE: 0.40146\n",
      "-- Epoch 33\n",
      "Training MSE: 0.39979\n",
      "-- Epoch 34\n",
      "Training MSE: 0.39804\n",
      "-- Epoch 35\n",
      "Training MSE: 0.39619\n",
      "-- Epoch 36\n",
      "Training MSE: 0.39412\n",
      "-- Epoch 37\n",
      "Training MSE: 0.39211\n",
      "-- Epoch 38\n",
      "Training MSE: 0.39008\n",
      "-- Epoch 39\n",
      "Training MSE: 0.38786\n",
      "-- Epoch 40\n",
      "Training MSE: 0.38571\n",
      "-- Epoch 41\n",
      "Training MSE: 0.38324\n",
      "-- Epoch 42\n",
      "Training MSE: 0.38090\n",
      "-- Epoch 43\n",
      "Training MSE: 0.37852\n",
      "-- Epoch 44\n",
      "Training MSE: 0.37606\n",
      "-- Epoch 45\n",
      "Training MSE: 0.37352\n",
      "-- Epoch 46\n",
      "Training MSE: 0.37093\n",
      "-- Epoch 47\n",
      "Training MSE: 0.36844\n",
      "-- Epoch 48\n",
      "Training MSE: 0.36592\n",
      "-- Epoch 49\n",
      "Training MSE: 0.36335\n",
      "-- Epoch 50\n",
      "Training MSE: 0.36089\n",
      "-- Epoch 51\n",
      "Training MSE: 0.35831\n",
      "-- Epoch 52\n",
      "Training MSE: 0.35588\n",
      "-- Epoch 53\n",
      "Training MSE: 0.35341\n",
      "-- Epoch 54\n",
      "Training MSE: 0.35102\n",
      "-- Epoch 55\n",
      "Training MSE: 0.34861\n",
      "-- Epoch 56\n",
      "Training MSE: 0.34637\n",
      "-- Epoch 57\n",
      "Training MSE: 0.34410\n",
      "-- Epoch 58\n",
      "Training MSE: 0.34188\n",
      "-- Epoch 59\n",
      "Training MSE: 0.33969\n",
      "-- Epoch 60\n",
      "Training MSE: 0.33762\n",
      "-- Epoch 61\n",
      "Training MSE: 0.33563\n",
      "-- Epoch 62\n",
      "Training MSE: 0.33359\n",
      "-- Epoch 63\n",
      "Training MSE: 0.33172\n",
      "-- Epoch 64\n",
      "Training MSE: 0.32984\n",
      "-- Epoch 65\n",
      "Training MSE: 0.32805\n",
      "-- Epoch 66\n",
      "Training MSE: 0.32627\n",
      "-- Epoch 67\n",
      "Training MSE: 0.32467\n",
      "-- Epoch 68\n",
      "Training MSE: 0.32300\n",
      "-- Epoch 69\n",
      "Training MSE: 0.32136\n",
      "-- Epoch 70\n",
      "Training MSE: 0.31990\n",
      "-- Epoch 71\n",
      "Training MSE: 0.31848\n",
      "-- Epoch 72\n",
      "Training MSE: 0.31706\n",
      "-- Epoch 73\n",
      "Training MSE: 0.31585\n",
      "-- Epoch 74\n",
      "Training MSE: 0.31452\n",
      "-- Epoch 75\n",
      "Training MSE: 0.31335\n",
      "-- Epoch 76\n",
      "Training MSE: 0.31210\n",
      "-- Epoch 77\n",
      "Training MSE: 0.31111\n",
      "-- Epoch 78\n",
      "Training MSE: 0.31004\n",
      "-- Epoch 79\n",
      "Training MSE: 0.30902\n",
      "-- Epoch 80\n",
      "Training MSE: 0.30815\n",
      "-- Epoch 81\n",
      "Training MSE: 0.30726\n",
      "-- Epoch 82\n",
      "Training MSE: 0.30643\n",
      "-- Epoch 83\n",
      "Training MSE: 0.30560\n",
      "-- Epoch 84\n",
      "Training MSE: 0.30485\n",
      "-- Epoch 85\n",
      "Training MSE: 0.30415\n",
      "-- Epoch 86\n",
      "Training MSE: 0.30345\n",
      "-- Epoch 87\n",
      "Training MSE: 0.30282\n",
      "-- Epoch 88\n",
      "Training MSE: 0.30219\n",
      "-- Epoch 89\n",
      "Training MSE: 0.30156\n",
      "-- Epoch 90\n",
      "Training MSE: 0.30115\n",
      "-- Epoch 91\n",
      "Training MSE: 0.30052\n",
      "-- Epoch 92\n",
      "Training MSE: 0.30013\n",
      "-- Epoch 93\n",
      "Training MSE: 0.29962\n",
      "-- Epoch 94\n",
      "Training MSE: 0.29924\n",
      "-- Epoch 95\n",
      "Training MSE: 0.29887\n",
      "-- Epoch 96\n",
      "Training MSE: 0.29844\n",
      "-- Epoch 97\n",
      "Training MSE: 0.29819\n",
      "-- Epoch 98\n",
      "Training MSE: 0.29773\n",
      "-- Epoch 99\n",
      "Training MSE: 0.29748\n",
      "-- Epoch 100\n",
      "Training MSE: 0.29707\n",
      "train:  0.594370616337  test:  0.894449652828\n"
     ]
    }
   ],
   "source": [
    "fm = pylibfm.FM(num_factors=14, num_iter=100, verbose=True, task=\"regression\", \n",
    "                initial_learning_rate=0.001, learning_rate_schedule=\"optimal\")\n",
    "fm.fit(X_train, y_train)\n",
    "train_score = mean_squared_error(y_train, fm.predict(X_train))\n",
    "test_score = mean_squared_error(y_test, fm.predict(X_test))\n",
    "print 'train: ', train_score, ' test: ', test_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 3.8576649]\n"
     ]
    }
   ],
   "source": [
    "ex = v.transform([{'user_id': '308', 'movie_id': '1'}])\n",
    "print fm.predict(ex)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Статистически FM лучше, но в данном кокретном эпизоде повела себя чуть хуже linear regression. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vowpal Wabbit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://habrahabr.ru/company/mlclass/blog/248779/ Когда данных действительно много: Vowpal Wabbit (@akrot)\n",
    "https://habrahabr.ru/company/ods/blog/326418/ Открытый курс машинного обучения. Тема 8. Обучение на гигабайтах с Vowpal Wabbit (Open Data Science)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('ml-100k/ua.base') as fh, open('train.vw', 'w') as vw:\n",
    "    for line in fh:\n",
    "        (user, movieid, rating, ts)=line.split('\\t')\n",
    "        vw.write('{rating} |u user:{user} |m movie:{movie}\\n'.format(\n",
    "            rating=rating, user=user, movie=movieid))\n",
    "\n",
    "with open('ml-100k/ua.test') as fh, open('test.vw', 'w') as vw:\n",
    "    for line in fh:\n",
    "        (user, movieid, rating, ts)=line.split('\\t')\n",
    "        vw.write('{rating} |u user:{user} |m movie:{movie}\\n'.format(\n",
    "            rating=rating, user=user, movie=movieid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final_regressor = model.vw\n",
      "Num weight bits = 29\n",
      "learning rate = 0.5\n",
      "initial_t = 0\n",
      "power_t = 0.5\n",
      "decay_learning_rate = 1\n",
      "creating cache_file = cache\n",
      "Reading datafile = train.vw\n",
      "num sources = 1\n",
      "average  since         example        example  current  current  current\n",
      "loss     last          counter         weight    label  predict features\n",
      "25.000000 25.000000            1            1.0   5.0000   0.0000        3\n",
      "14.381521 3.763042            2            2.0   3.0000   1.0601        3\n",
      "9.299075 4.216629            4            4.0   3.0000   1.7951        3\n",
      "6.438642 3.578208            8            8.0   1.0000   2.8163        3\n",
      "4.745547 3.052453           16           16.0   3.0000   3.8444        3\n",
      "3.134292 1.523038           32           32.0   2.0000   2.8383        3\n",
      "2.143737 1.153181           64           64.0   1.0000   3.7473        3\n",
      "2.005677 1.867618          128          128.0   4.0000   2.9109        3\n",
      "1.732375 1.459073          256          256.0   4.0000   3.7371        3\n",
      "1.834211 1.936046          512          512.0   5.0000   2.8074        3\n",
      "1.530229 1.226248         1024         1024.0   3.0000   3.3625        3\n",
      "1.529839 1.529449         2048         2048.0   3.0000   3.5993        3\n",
      "1.368792 1.207745         4096         4096.0   4.0000   3.7780        3\n",
      "1.218920 1.069047         8192         8192.0   5.0000   3.5081        3\n",
      "1.207996 1.197073        16384        16384.0   3.0000   3.3259        3\n",
      "1.172874 1.137751        32768        32768.0   2.0000   3.6545        3\n",
      "1.155978 1.139083        65536        65536.0   4.0000   3.6415        3\n",
      "1.210399 1.210399       131072       131072.0   3.0000   3.9090        3 h\n",
      "1.210201 1.210004       262144       262144.0   5.0000   3.5868        3 h\n",
      "\n",
      "finished run\n",
      "number of examples per pass = 81513\n",
      "passes used = 4\n",
      "weighted example sum = 326052.000000\n",
      "weighted label sum = 1148632.000000\n",
      "average loss = 1.157558 h\n",
      "best constant = 3.522849\n",
      "total feature number = 978156\n"
     ]
    }
   ],
   "source": [
    "!vw --loss_function squared train.vw -b 29 --passes 5 --cache_file cache -f model.vw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num weight bits = 29\n",
      "learning rate = 0.5\n",
      "initial_t = 0\n",
      "power_t = 0.5\n",
      "using no cache\n",
      "Reading datafile = test.vw\n",
      "num sources = 1\n",
      "average  since         example        example  current  current  current\n",
      "loss     last          counter         weight    label  predict features\n",
      "5.996206 5.996206            1            1.0   4.0000   1.5513        3\n",
      "4.226705 2.457205            2            2.0   4.0000   2.4325        3\n",
      "2.399238 0.571770            4            4.0   3.0000   3.5336        3\n",
      "2.158566 1.917895            8            8.0   3.0000   3.4092        3\n",
      "1.774687 1.390807           16           16.0   3.0000   3.7884        3\n",
      "2.151676 2.528665           32           32.0   4.0000   2.6427        3\n",
      "1.994070 1.836465           64           64.0   3.0000   3.4915        3\n",
      "1.529432 1.064793          128          128.0   4.0000   4.0766        3\n",
      "1.606020 1.682608          256          256.0   3.0000   3.7606        3\n",
      "1.350834 1.095647          512          512.0   4.0000   3.5630        3\n",
      "1.289408 1.227982         1024         1024.0   3.0000   3.3484        3\n",
      "1.306678 1.323949         2048         2048.0   4.0000   3.3871        3\n",
      "1.225587 1.144495         4096         4096.0   3.0000   3.2708        3\n",
      "1.237257 1.248926         8192         8192.0   2.0000   3.7169        3\n",
      "\n",
      "finished run\n",
      "number of examples per pass = 9430\n",
      "passes used = 1\n",
      "weighted example sum = 9430.000000\n",
      "weighted label sum = 33833.000000\n",
      "average loss = 1.229125\n",
      "best constant = 3.587805\n",
      "total feature number = 28290\n"
     ]
    }
   ],
   "source": [
    "!vw --loss_function squared -i model.vw test.vw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final_regressor = model.vw\n",
      "creating low rank quadratic features for pairs: um14 \n",
      "Num weight bits = 29\n",
      "learning rate = 0.5\n",
      "initial_t = 0\n",
      "power_t = 0.5\n",
      "decay_learning_rate = 1\n",
      "creating cache_file = cache\n",
      "Reading datafile = train.vw\n",
      "num sources = 1\n",
      "average  since         example        example  current  current  current\n",
      "loss     last          counter         weight    label  predict features\n",
      "25.000000 25.000000            1            1.0   5.0000   0.0000        3\n",
      "14.500000 4.000000            2            2.0   3.0000   5.0000        3\n",
      "7.673673 0.847346            4            4.0   3.0000   3.8256        3\n",
      "5.585479 3.497286            8            8.0   1.0000   4.2263        3\n",
      "4.207890 2.830300           16           16.0   3.0000   4.9807        3\n",
      "2.995360 1.782831           32           32.0   2.0000   2.1405        3\n",
      "2.074197 1.153034           64           64.0   1.0000   3.6647        3\n",
      "2.098773 2.123349          128          128.0   4.0000   2.1646        3\n",
      "1.894462 1.690150          256          256.0   4.0000   3.5794        3\n",
      "2.028764 2.163067          512          512.0   5.0000   2.6327        3\n",
      "1.684760 1.340756         1024         1024.0   3.0000   3.1179        3\n",
      "1.594485 1.504210         2048         2048.0   3.0000   4.1025        3\n",
      "1.379674 1.164864         4096         4096.0   4.0000   3.8819        3\n",
      "1.221207 1.062739         8192         8192.0   5.0000   3.6725        3\n",
      "1.194231 1.167256        16384        16384.0   3.0000   3.3936        3\n",
      "1.151618 1.109004        32768        32768.0   2.0000   3.8339        3\n",
      "1.128993 1.106368        65536        65536.0   4.0000   3.8179        3\n",
      "1.178586 1.178586       131072       131072.0   3.0000   3.8563        3 h\n",
      "1.184498 1.190409       262144       262144.0   5.0000   3.6205        3 h\n",
      "\n",
      "finished run\n",
      "number of examples per pass = 81513\n",
      "passes used = 4\n",
      "weighted example sum = 326052.000000\n",
      "weighted label sum = 1148632.000000\n",
      "average loss = 1.120113 h\n",
      "best constant = 3.522849\n",
      "total feature number = 978156\n"
     ]
    }
   ],
   "source": [
    "!vw --loss_function squared train.vw -b 29 --lrq um14 --passes 5 --cache_file cache -f model.vw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating low rank quadratic features for pairs: um14 \n",
      "Num weight bits = 29\n",
      "learning rate = 0.5\n",
      "initial_t = 0\n",
      "power_t = 0.5\n",
      "using no cache\n",
      "Reading datafile = test.vw\n",
      "num sources = 1\n",
      "average  since         example        example  current  current  current\n",
      "loss     last          counter         weight    label  predict features\n",
      "6.908770 6.908770            1            1.0   4.0000   1.3715        3\n",
      "3.954385 1.000000            2            2.0   4.0000   5.0000        3\n",
      "3.170250 2.386114            4            4.0   3.0000   5.0000        3\n",
      "2.833448 2.496647            8            8.0   3.0000   4.3165        3\n",
      "2.450947 2.068445           16           16.0   3.0000   3.2628        3\n",
      "2.554576 2.658206           32           32.0   4.0000   2.6436        3\n",
      "2.165291 1.776006           64           64.0   3.0000   4.2277        3\n",
      "1.714051 1.262811          128          128.0   4.0000   3.8675        3\n",
      "1.697511 1.680971          256          256.0   3.0000   3.8690        3\n",
      "1.416145 1.134779          512          512.0   4.0000   3.6455        3\n",
      "1.320989 1.225834         1024         1024.0   3.0000   3.4087        3\n",
      "1.324566 1.328142         2048         2048.0   4.0000   3.2788        3\n",
      "1.230803 1.137041         4096         4096.0   3.0000   2.9843        3\n",
      "1.242380 1.253957         8192         8192.0   2.0000   3.8026        3\n",
      "\n",
      "finished run\n",
      "number of examples per pass = 9430\n",
      "passes used = 1\n",
      "weighted example sum = 9430.000000\n",
      "weighted label sum = 33833.000000\n",
      "average loss = 1.233394\n",
      "best constant = 3.587805\n",
      "total feature number = 28290\n"
     ]
    }
   ],
   "source": [
    "!vw --loss_function squared -i model.vw test.vw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final_regressor = model.vw\n",
      "Num weight bits = 29\n",
      "learning rate = 0.5\n",
      "initial_t = 0\n",
      "power_t = 0.5\n",
      "decay_learning_rate = 1\n",
      "creating cache_file = cache\n",
      "Reading datafile = train.vw\n",
      "num sources = 1\n",
      "average  since         example        example  current  current  current\n",
      "loss     last          counter         weight    label  predict features\n",
      "25.000000 25.000000            1            1.0   5.0000   0.0000        3\n",
      "14.500000 4.000000            2            2.0   3.0000   5.0000        3\n",
      "7.673719 0.847438            4            4.0   3.0000   3.8255        3\n",
      "5.585484 3.497250            8            8.0   1.0000   4.2263        3\n",
      "4.207909 2.830333           16           16.0   3.0000   4.9807        3\n",
      "2.995374 1.782839           32           32.0   2.0000   2.1405        3\n",
      "2.074204 1.153033           64           64.0   1.0000   3.6647        3\n",
      "2.098776 2.123348          128          128.0   4.0000   2.1646        3\n",
      "1.894464 1.690151          256          256.0   4.0000   3.5794        3\n",
      "2.028768 2.163072          512          512.0   5.0000   2.6327        3\n",
      "1.684764 1.340760         1024         1024.0   3.0000   3.1179        3\n",
      "1.594488 1.504212         2048         2048.0   3.0000   4.1025        3\n",
      "1.379676 1.164865         4096         4096.0   4.0000   3.8819        3\n",
      "1.221208 1.062739         8192         8192.0   5.0000   3.6725        3\n",
      "1.194232 1.167256        16384        16384.0   3.0000   3.3936        3\n",
      "1.151618 1.109004        32768        32768.0   2.0000   3.8339        3\n",
      "1.128993 1.106368        65536        65536.0   4.0000   3.8179        3\n",
      "1.178586 1.178586       131072       131072.0   3.0000   3.8563        3 h\n",
      "1.184497 1.190408       262144       262144.0   5.0000   3.6205        3 h\n",
      "\n",
      "finished run\n",
      "number of examples per pass = 81513\n",
      "passes used = 4\n",
      "weighted example sum = 326052.000000\n",
      "weighted label sum = 1148632.000000\n",
      "average loss = 1.120113 h\n",
      "best constant = 3.522849\n",
      "total feature number = 978156\n"
     ]
    }
   ],
   "source": [
    "!vw --loss_function squared train.vw -b 29 --lrqfa um14 --passes 5 --cache_file cache -f model.vw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num weight bits = 29\r\n",
      "learning rate = 0.5\r\n",
      "initial_t = 0\r\n",
      "power_t = 0.5\r\n",
      "using no cache\r\n",
      "Reading datafile = test.vw\r\n",
      "num sources = 1\r\n",
      "average  since         example        example  current  current  current\r\n",
      "loss     last          counter         weight    label  predict features\r\n",
      "6.908787 6.908787            1            1.0   4.0000   1.3715        3\r\n",
      "3.954393 1.000000            2            2.0   4.0000   5.0000        3\r\n",
      "3.170230 2.386066            4            4.0   3.0000   5.0000        3\r\n",
      "2.833476 2.496722            8            8.0   3.0000   4.3166        3\r\n",
      "2.450954 2.068432           16           16.0   3.0000   3.2628        3\r\n",
      "2.554575 2.658196           32           32.0   4.0000   2.6437        3\r\n",
      "2.165282 1.775990           64           64.0   3.0000   4.2277        3\r\n",
      "1.714047 1.262812          128          128.0   4.0000   3.8675        3\r\n",
      "1.697512 1.680978          256          256.0   3.0000   3.8690        3\r\n",
      "1.416144 1.134777          512          512.0   4.0000   3.6455        3\r\n",
      "1.320989 1.225833         1024         1024.0   3.0000   3.4087        3\r\n",
      "1.324566 1.328143         2048         2048.0   4.0000   3.2788        3\r\n",
      "1.230803 1.137041         4096         4096.0   3.0000   2.9843        3\r\n",
      "1.242380 1.253957         8192         8192.0   2.0000   3.8026        3\r\n",
      "\r\n",
      "finished run\r\n",
      "number of examples per pass = 9430\r\n",
      "passes used = 1\r\n",
      "weighted example sum = 9430.000000\r\n",
      "weighted label sum = 33833.000000\r\n",
      "average loss = 1.233394\r\n",
      "best constant = 3.587805\r\n",
      "total feature number = 28290\r\n"
     ]
    }
   ],
   "source": [
    "!vw --loss_function squared -i model.vw test.vw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LibFFM and classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/guestwalk/libffm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "File format is similar to LibSVM: \n",
    "```\n",
    "<label> <field1>:<index1>:<value1> <field2>:<index2>:<value2> ...\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('ml-100k/ua.base') as fh, open('train.libffm', 'w') as vw:\n",
    "    for line in fh:\n",
    "        (user, movieid, rating, ts)=line.split('\\t')\n",
    "        rating = int(rating)\n",
    "        label = -1 if rating == 1 else 1\n",
    "        vw.write('{label} u:{user}:1 m:{movie}:1\\n'.format(\n",
    "            label=label, user=user, movie=movieid))\n",
    "\n",
    "with open('ml-100k/ua.test') as fh, open('test.libffm', 'w') as vw:\n",
    "    for line in fh:\n",
    "        (user, movieid, rating, ts)=line.split('\\t')\n",
    "        rating = int(rating)\n",
    "        if rating in {2, 3, 4}:\n",
    "            continue\n",
    "        label = -1 if rating == 1 else 1\n",
    "        vw.write('{label} u:{user}:1 m:{movie}:1\\n'.format(\n",
    "            label=label, user=user, movie=movieid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter   tr_logloss   va_logloss\n",
      "   1      0.33135      0.45627\n",
      "   2      0.25695      0.45696\n",
      "   3      0.25340      0.45518\n",
      "   4      0.25215      0.45604\n",
      "   5      0.25150      0.45771\n",
      "   6      0.25071      0.45612\n",
      "   7      0.25058      0.45815\n",
      "   8      0.25047      0.45632\n",
      "   9      0.25020      0.45643\n",
      "  10      0.24997      0.45812\n",
      "  11      0.24990      0.45714\n",
      "  12      0.24948      0.45746\n",
      "  13      0.24975      0.45848\n",
      "  14      0.24929      0.45791\n",
      "  15      0.24941      0.45771\n",
      "  16      0.24935      0.45808\n",
      "  17      0.24933      0.45783\n",
      "  18      0.24911      0.45840\n",
      "  19      0.24889      0.45856\n",
      "  20      0.24910      0.45799\n",
      "  21      0.24878      0.45867\n",
      "  22      0.24911      0.45767\n",
      "  23      0.24901      0.45831\n",
      "  24      0.24862      0.45803\n",
      "  25      0.24896      0.45728\n",
      "  26      0.24870      0.45716\n",
      "  27      0.24910      0.45851\n",
      "  28      0.24857      0.45817\n",
      "  29      0.24870      0.45805\n",
      "  30      0.24869      0.45848\n",
      "  31      0.24837      0.45771\n",
      "  32      0.24884      0.45867\n",
      "  33      0.24842      0.45810\n",
      "  34      0.24855      0.45826\n",
      "  35      0.24871      0.45813\n",
      "  36      0.24873      0.45763\n",
      "  37      0.24848      0.45747\n",
      "  38      0.24832      0.45797\n",
      "  39      0.24872      0.45836\n",
      "  40      0.24812      0.45790\n",
      "  41      0.24829      0.45827\n",
      "  42      0.24836      0.45845\n",
      "  43      0.24844      0.45840\n",
      "  44      0.24858      0.45796\n",
      "  45      0.24822      0.45806\n",
      "  46      0.24828      0.45841\n",
      "  47      0.24838      0.45814\n",
      "  48      0.24831      0.45797\n",
      "  49      0.24834      0.45827\n",
      "  50      0.24853      0.45837\n"
     ]
    }
   ],
   "source": [
    "!ffm-train -p test.libffm -l 0.05 -t 50 -k 14 train.libffm model.libffm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logloss = 0.48078\r\n"
     ]
    }
   ],
   "source": [
    "!ffm-predict test.libffm model.libffm output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "idx = (y_train == 5) | (y_train == 1)\n",
    "y_train_label = y_train[idx]\n",
    "X_train_bin = X_train[idx]\n",
    "\n",
    "idx = (y_test == 5) | (y_test == 1)\n",
    "y_test_label = y_test[idx]\n",
    "X_test_bin = X_test[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_train_label = (y_train_label - 1) / 4\n",
    "y_test_label = (y_test_label - 1) / 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.24903047224116151, 0.30373051559950098)"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = LogisticRegression()\n",
    "lr.fit(X_train_bin, y_train_label)\n",
    "train_score = log_loss(y_train_label, lr.predict_proba(X_train_bin))\n",
    "test_score = log_loss(y_test_label, lr.predict_proba(X_test_bin))\n",
    "train_score, test_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
